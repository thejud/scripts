#!/usr/bin/env python
"""trivial field extractor for json

jx is intended to be used to trivially extract fields from json data.
Text table format is the default output format, but can be changed to 
TSV with the -t option, or to another delimiter with with the -d option.

jx also provide (basic) flattening for extracting nested fields.
nested json can be flattened with --flatten, and if so, nested keys
can be references with the syntax key1 + _ + key2 + index
e.g. name_first or addresses_0_zipcode
Use --join to join keys with a different delimiter, like "."

jq is a much better alternative for many things, but for my
comon use case of slicing out some fields, it's overly verbose.

EXAMPLES:
    # field extraction
    $ echo '{"a": 1, "b": 2, "c":3}' | jx c a
    c  a
    3  1

    # columnar output is the default. No fields prints all values
    $ printf '{"a": "foo", "b": 1}\n{"a":"loooooong", "b":2}' | jx 
    foo        1
    loooooong  2

    # no headers
    $ echo '{"a": 1, "b": 2, "c":3}' | jx -H c a
    3  1

    # flatten
    $ echo '{"a": {"b": 2, "c":3, "d":[5,6] }}' | jx -F a_c a_b
    a_c  a_b
    3    2

    # flatten with array indexing
    $ echo '{"a": {"b": 2, "c":3, "d": [7,10]}}' | jx -F a_c a_d_0
    a_c	 a_d_0
    3    7

    # get field names from first line
    echo '{"a": 1, "b": 2, "c":3}' | jx --names
    a
    b
    c

    # alternate json level joiner. Default is '.'
    $  echo '{"a": {"b": 2, "c":3, "d":[5,6] }}' | jx -F -j. a.c a.b
    a.c  a.b
    3    2  
    
    # tab-separated output
    $ echo '{"a":1, "b": 2, "c":3}' | jx  -t a c
    a	c
    1	3

    # alternate output delimiter
    $ echo '{"a":1, "b": 2, "c":3}' | jx  -s '|'  a c
    a|c
    1|3




TODO:
    Add positional field extraction. Will require validation of fields on every
    line to match the first line to prevent silently dropping/munging columns

"""

from __future__ import print_function
import argparse
import json
import logging
import sys

class Flattener:
    def __init__(self, joiner="_"):
        self.joiner = joiner

    def flatten(self, data, out=None, prefix=None):
        out = {} if out is None else out
        prefix = [] if prefix is None else prefix

        if isinstance(data, dict):
            for k,value in data.items():
                self.flatten(value, out, prefix + [k])
        elif isinstance(data, list):
            for counter, value in enumerate(data):
                self.flatten(value, out, prefix + [counter])
        else:
            key = self.joiner.join([str(s) for s in prefix])
            logging.debug(f"writing {data} to {key}")
            out[key] = data
        return out

class ColumnPrinter:
    def __init__(self):
        self.rows = []

    def print(self, columns):
        self.rows.append(columns)

    def flush(self):
        # https://stackoverflow.com/a/12065663
        widths = [max(map(len, col)) for col in zip(*self.rows)]
        for row in self.rows:
            print("  ".join((val.ljust(width) for val, width in zip(row,
                widths))))


class DelimitedPrinter:
    def __init__(self, joiner):
        self.joiner=joiner

    def print(self, columns):
        print(self.joiner.join(columns))
    
    def flush(self):
        pass

def parse_args():
    parser = argparse.ArgumentParser(
            description="%(prog)s extract fields easily from json")

    group=parser.add_mutually_exclusive_group()
    group.add_argument('-t', '--tsv', action='store_const', const="\t",
            dest="delimiter", help='tab-delimited output. Also see --delimiter')
    group.add_argument('-d', '--delimiter', help='delimiter for json fields/columns')

    parser.add_argument('-F', '--flatten', action='store_true',
            help='flatten json before selecting. uses the --joiner')
    parser.add_argument('-j', '--joiner',
            help='joiner for keynames when flattening levels, ' + 
                'e.g. "key1_key2". Default: %(default)s', default='_')
    parser.add_argument('-H', '--headers', action='store_true',
            help="skip header printing")
    parser.add_argument('-n', '--names', action='store_true',
            help='show column names from initial object and exit')
    parser.add_argument('fields', nargs="*",
            help="list of field names to extract")

    return parser.parse_args()

def run():
    opts = parse_args()
    out=sys.stdout
    if opts.delimiter is not None:
        printer = DelimitedPrinter(opts.delimiter)
    else:
        printer = ColumnPrinter()

    flattener = Flattener(joiner=opts.joiner)

    if opts.fields and not opts.headers:
        printer.print(opts.fields)

    for line in sys.stdin:
        data = json.loads(line.strip())
        if opts.flatten:
            data = flattener.flatten(data)
        if opts.names:
            for k in data.keys():
                print(k)
            return
        logging.debug(data.keys())

        # if we have a list of fields, use them. Otherwise, print all keys
        fields = [ str(data.get(f, "")) for f in opts.fields or data.keys()]

        logging.debug(fields)
        printer.print(fields)

    printer.flush()

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    run()
