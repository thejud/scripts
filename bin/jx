#!/usr/bin/env python
"""trivial field extractor for json

jx is intended to be used to trivially extract fields from json data.
Text table format is the default output format, but can be changed to 
TSV with the -t option, or to another delimiter with with the -d option.

jx will also auto-detect array input, and paginated input by
looking at the first line, so you can send paginated results (with
a total and items key in the first line), or first line starts with '['
use -s/--smart to disable this smartness

jx also provide (basic) flattening for extracting nested fields.
nested json can be flattened with --flatten, and if so, nested keys
can be references with the syntax key1 + _ + key2 + index
e.g. name_first or addresses_0_zipcode
Use --join to join keys with a different delimiter, like "."

jq is a much better alternative for many things, but for my
comon use case of slicing out some fields, it's overly verbose.

EXAMPLES:
    # field extraction
    $ echo '{"a": 1, "b": 2, "c":3}' | jx c a
    c  a
    3  1

    # columnar output is the default. No fields prints all values
    $ printf '{"a": "foo", "b": 1}\n{"a":"loooooong", "b":2}' | jx 
    foo        1
    loooooong  2

    # no headers
    $ echo '{"a": 1, "b": 2, "c":3}' | jx -H c a
    3  1

    # flatten
    $ echo '{"a": {"b": 2, "c":3, "d":[5,6] }}' | jx -F a_c a_b
    a_c  a_b
    3    2

    # flatten with array indexing
    $ echo '{"a": {"b": 2, "c":3, "d": [7,10]}}' | jx -F a_c a_d_0
    a_c	 a_d_0
    3    7

    # get field names from first line
    echo '{"a": 1, "b": 2, "c":3}' | jx --names
    a
    b
    c

    # alternate json level joiner. Default is '.'
    $  echo '{"a": {"b": 2, "c":3, "d":[5,6] }}' | jx -F -j. a.c a.b
    a.c  a.b
    3    2  
    
    # tab-separated output
    $ echo '{"a":1, "b": 2, "c":3}' | jx  -t a c
    a	c
    1	3

    # alternate output delimiter
    $ echo '{"a":1, "b": 2, "c":3}' | jx  -s '|'  a c
    a|c
    1|3

    # smart parsing: autodetect arrays
    $ echo '[{'a':1},{'a':2}]' | jx a
    a
    1
    2

    # smart parsing: autodetect paged sets (with items and total)
    $ echo '{"total":2,"items":[{"a":1},{"a":2"}]}' | jx a
    a
    1
    2

    # turn off smart parsing
    $ echo '{"total":2,"items":[{"a":1},{"a":2}]}' | jx -s items
    items
    [{"a":1},{"a":2}]}
    
TODO:
    Add positional field extraction. Will require validation of fields on every
    line to match the first line to prevent silently dropping/munging columns

"""

from __future__ import print_function
import argparse
import json
import logging
import sys

class Flattener:
    def __init__(self, joiner="_"):
        self.joiner = joiner

    def flatten(self, data, out=None, prefix=None):
        out = {} if out is None else out
        prefix = [] if prefix is None else prefix

        if isinstance(data, dict):
            for k,value in data.items():
                self.flatten(value, out, prefix + [k])
        elif isinstance(data, list):
            for counter, value in enumerate(data):
                self.flatten(value, out, prefix + [counter])
        else:
            key = self.joiner.join([str(s) for s in prefix])
            logging.debug(f"writing {data} to {key}")
            out[key] = data
        return out

class ColumnPrinter:
    def __init__(self):
        self.rows = []

    def print(self, columns):
        self.rows.append(columns)

    def flush(self):
        # https://stackoverflow.com/a/12065663
        widths = [max(map(len, col)) for col in zip(*self.rows)]
        for row in self.rows:
            print("  ".join((val.ljust(width) for val, width in zip(row,
                widths))))


class DelimitedPrinter:
    def __init__(self, joiner):
        self.joiner=joiner

    def print(self, columns):
        print(self.joiner.join(columns))
    
    def flush(self):
        pass

def parse_args():
    parser = argparse.ArgumentParser(
            description="%(prog)s extract fields easily from json")

    group=parser.add_mutually_exclusive_group()
    group.add_argument('-t', '--tsv', action='store_const', const="\t",
            dest="delimiter", help='tab-delimited output. Also see --delimiter')
    group.add_argument('-d', '--delimiter', help='delimiter for json fields/columns')

    parser.add_argument('-F', '--flatten', action='store_true',
            help='flatten json before selecting. uses the --joiner')
    parser.add_argument('-j', '--joiner',
            help='joiner for keynames when flattening levels, ' + 
                'e.g. "key1_key2". Default: %(default)s', default='_')
    parser.add_argument('-H', '--headers', action='store_true',
            help="skip header printing")
    parser.add_argument('-n', '--names', action='store_true',
            help='show column names from initial object and exit')
    parser.add_argument('-s', '--smart', action='store_false',
            default='True',
            help='disable smart detection of arrays and paginated results')
    parser.add_argument('-D', '--debug', action='store_true',
            help='debug')
    parser.add_argument('fields', nargs="*",
            help="list of field names to extract")

    return parser.parse_args()

def read(fh, opts):
    first = True
    for line in fh:
        if not line.strip(): 
            logging.debug('skipping')
            next
        logging.debug(f">>>{line.strip()}<" + "\n")
        if opts.smart and first:
            logging.debug('smartly checking first line')
            first = False
            if line.startswith('['):
                logging.info('smart detected an array')
                for item in json.loads(line):
                    yield item
            else:
                logging.debug('checking pagination')
                parsed = json.loads(line)
                if 'items' in parsed and 'total' in parsed:
                    logging.info('smart detected a paged set')
                    for item in parsed['items']:
                        yield  item
                else:
                    yield parsed
        else:
            yield json.loads(line)

def run():
    opts = parse_args()
    if opts.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    out=sys.stdout
    if opts.delimiter is not None:
        printer = DelimitedPrinter(opts.delimiter)
    else:
        printer = ColumnPrinter()

    flattener = Flattener(joiner=opts.joiner)

    if opts.fields and not opts.headers:
        printer.print(opts.fields)

    for data in read(sys.stdin, opts):
        if opts.flatten:
            data = flattener.flatten(data)
        if opts.names:
            for k in data.keys():
                print(k)
            return
        logging.debug(data.keys())

        # if we have a list of fields, use them. Otherwise, print all keys
        fields = [ str(data.get(f, "")) for f in opts.fields or data.keys()]

        logging.debug(fields)
        printer.print(fields)

    printer.flush()

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    run()
